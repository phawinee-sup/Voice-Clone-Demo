{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6379e0b7",
   "metadata": {},
   "source": [
    "Pipeline ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°\n",
    "\n",
    "Download audio ‡∏à‡∏≤‡∏Å YouTube (wav)\n",
    "\n",
    "Normalize format ‚Üí mono / 22050 Hz\n",
    "\n",
    "‡∏ï‡∏±‡∏î silence + ‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ (VAD)\n",
    "\n",
    "‡πÅ‡∏¢‡∏Å‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î (Speaker Diarization)\n",
    "\n",
    "‡∏ï‡∏±‡πâ‡∏á label ‡∏ú‡∏π‡πâ‡∏û‡∏π‡∏î ‚Üí filter ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ speaker ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "\n",
    "‡πÑ‡∏î‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢:\n",
    "1 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ = 1 wav / speaker ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß / ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏û‡∏•‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc86980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install yt-dlp torch torchaudio pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9c48bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y torch torchvision torchaudio\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e66489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6257bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Phonenet\\anaconda3\\envs\\audioenv\\lib\\site-packages\\pyannote\\audio\\core\\io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from pyannote.audio import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6102c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_audio(youtube_id, out_dir=\"yt_audio\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    url = f\"https://www.youtube.com/watch?v={youtube_id}\"\n",
    "\n",
    "    cmd = [\n",
    "        \"yt-dlp\",\n",
    "        \"-f\", \"bestaudio/best\",\n",
    "        \"--extract-audio\",\n",
    "        \"--audio-format\", \"wav\",\n",
    "        \"--audio-quality\", \"0\",\n",
    "        \"--ffmpeg-location\", \"C:\\\\ffmpeg\\\\bin\",  # üîß ‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á\n",
    "        \"--postprocessor-args\", \"ffmpeg:-ac 1\",  # mono only\n",
    "        \"-o\", f\"{out_dir}/{youtube_id}.%(ext)s\",\n",
    "        url\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(result.stderr)\n",
    "        raise RuntimeError(\"yt-dlp failed\")\n",
    "\n",
    "    print(f\"‚úÖ downloaded {youtube_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f4ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_audio(input_wav, output_wav, sr):\n",
    "    audio, _ = librosa.load(input_wav, sr=sr, mono=True)\n",
    "    sf.write(output_wav, audio, sr, subtype=\"PCM_16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea1b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Phonenet/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    }
   ],
   "source": [
    "model, utils = torch.hub.load(\n",
    "    \"snakers4/silero-vad\",\n",
    "    \"silero_vad\",\n",
    "    trust_repo=True\n",
    ")\n",
    "\n",
    "(get_speech_timestamps, _, read_audio, _, _) = utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c464d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences_16k(wav_16k_path):\n",
    "    wav = read_audio(wav_16k_path, sampling_rate=16000)\n",
    "    timestamps = get_speech_timestamps(\n",
    "        wav,\n",
    "        model,\n",
    "        sampling_rate=16000\n",
    "    )\n",
    "    return timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba92dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Phonenet\\anaconda3\\envs\\audioenv\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  backend = torchaudio.get_audio_backend()\n",
      "c:\\Users\\Phonenet\\anaconda3\\envs\\audioenv\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n",
      "c:\\Users\\Phonenet\\anaconda3\\envs\\audioenv\\lib\\site-packages\\pyannote\\audio\\pipelines\\speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(backend)\n",
      "c:\\Users\\Phonenet\\anaconda3\\envs\\audioenv\\lib\\site-packages\\pyannote\\audio\\tasks\\segmentation\\mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "    \n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=os.environ[\"HF_TOKEN\"]\n",
    ")\n",
    "\n",
    "\n",
    "def diarize(wav_16k_path):\n",
    "    diarization = pipeline(wav_16k_path)\n",
    "    segments = []\n",
    "\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        segments.append({\n",
    "            \"start\": turn.start,\n",
    "            \"end\": turn.end,\n",
    "            \"speaker\": speaker\n",
    "        })\n",
    "\n",
    "    return segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d1780dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_speakers(diar_segments):\n",
    "    stats = {}\n",
    "\n",
    "    for seg in diar_segments:\n",
    "        spk = seg[\"speaker\"]\n",
    "        dur = seg[\"end\"] - seg[\"start\"]\n",
    "        stats.setdefault(spk, 0.0)\n",
    "        stats[spk] += dur\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0315da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_speaker_for_sentence(sentence, diar_segments):\n",
    "    s_start = sentence[\"start\"] / 16000\n",
    "    s_end = sentence[\"end\"] / 16000\n",
    "\n",
    "    best_speaker = None\n",
    "    best_overlap = 0.0\n",
    "\n",
    "    for seg in diar_segments:\n",
    "        overlap = max(\n",
    "            0,\n",
    "            min(s_end, seg[\"end\"]) - max(s_start, seg[\"start\"])\n",
    "        )\n",
    "        if overlap > best_overlap:\n",
    "            best_overlap = overlap\n",
    "            best_speaker = seg[\"speaker\"]\n",
    "\n",
    "    return best_speaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9671c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_sentences_22k(\n",
    "    wav_22k_path,\n",
    "    sentences,\n",
    "    diar_segments,\n",
    "    out_dir,\n",
    "    target_speaker=None\n",
    "):\n",
    "    audio, sr = librosa.load(wav_22k_path, sr=22050, mono=True)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for sent in sentences:\n",
    "        speaker = find_speaker_for_sentence(sent, diar_segments)\n",
    "\n",
    "        if target_speaker and speaker != target_speaker:\n",
    "            continue\n",
    "\n",
    "        start = int((sent[\"start\"] / 16000) * sr)\n",
    "        end = int((sent[\"end\"] / 16000) * sr)\n",
    "\n",
    "        chunk = audio[start:end]\n",
    "        if len(chunk) < sr * 0.3:  # skip too short\n",
    "            continue\n",
    "\n",
    "        fname = f\"{speaker}_sent_{idx:04d}.wav\"\n",
    "        sf.write(os.path.join(out_dir, fname), chunk, sr)\n",
    "        idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a48d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_speaker_preview(wav_22k_path, diar_segments, out_dir, max_sec=20):\n",
    "    audio, sr = librosa.load(wav_22k_path, sr=22050, mono=True)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    acc = {}\n",
    "    for seg in diar_segments:\n",
    "        spk = seg[\"speaker\"]\n",
    "        if acc.get(spk, 0) >= max_sec:\n",
    "            continue\n",
    "\n",
    "        start = int(seg[\"start\"] * sr)\n",
    "        end = int(seg[\"end\"] * sr)\n",
    "        chunk = audio[start:end]\n",
    "\n",
    "        sf.write(\n",
    "            f\"{out_dir}/{spk}_preview.wav\",\n",
    "            chunk,\n",
    "            sr\n",
    "        )\n",
    "        acc[spk] = acc.get(spk, 0) + (seg[\"end\"] - seg[\"start\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee034cb",
   "metadata": {},
   "source": [
    "Phase 1 ‚Äî ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå speaker (‡∏ó‡∏≥‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)\n",
    "\n",
    "download\n",
    "\n",
    "convert ‚Üí 16k / 22k\n",
    "\n",
    "diarization\n",
    "\n",
    "‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î\n",
    "\n",
    "export preview ‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á\n",
    "\n",
    "Phase 2 ‚Äî export dataset (‡∏´‡∏•‡∏±‡∏á‡∏£‡∏π‡πâ speaker ‡πÅ‡∏•‡πâ‡∏ß)\n",
    "\n",
    "load sentence (VAD)\n",
    "\n",
    "match speaker\n",
    "\n",
    "export wav 22k\n",
    "\n",
    "üìå 1 file = 1 sentence + speaker ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8640366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Analyze AxUEkqPH7iQ\n",
      "‚úÖ downloaded AxUEkqPH7iQ\n",
      "Speaker summary:\n",
      "  SPEAKER_01: 1758.4 sec\n",
      "  SPEAKER_00: 987.0 sec\n",
      "  SPEAKER_02: 47.8 sec\n",
      "  SPEAKER_03: 30.1 sec\n",
      "  SPEAKER_04: 25.6 sec\n",
      "üëâ ‡∏ü‡∏±‡∏á preview ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏î‡∏ß‡πà‡∏≤ speaker ‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
      "\n",
      "üé¨ Analyze zbo7Mk3ryaI\n",
      "‚úÖ downloaded zbo7Mk3ryaI\n",
      "Speaker summary:\n",
      "  SPEAKER_00: 1822.0 sec\n",
      "  SPEAKER_01: 648.8 sec\n",
      "  SPEAKER_02: 96.4 sec\n",
      "üëâ ‡∏ü‡∏±‡∏á preview ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏î‡∏ß‡πà‡∏≤ speaker ‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
      "\n",
      "üé¨ Analyze PYkZ1Z2pEc8\n",
      "‚úÖ downloaded PYkZ1Z2pEc8\n",
      "Speaker summary:\n",
      "  SPEAKER_03: 3235.8 sec\n",
      "  SPEAKER_01: 579.0 sec\n",
      "  SPEAKER_02: 402.9 sec\n",
      "  SPEAKER_04: 266.5 sec\n",
      "  SPEAKER_00: 196.9 sec\n",
      "üëâ ‡∏ü‡∏±‡∏á preview ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏î‡∏ß‡πà‡∏≤ speaker ‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
      "\n",
      "üé¨ Analyze VN2VeBgR_3g\n",
      "‚úÖ downloaded VN2VeBgR_3g\n",
      "Speaker summary:\n",
      "  SPEAKER_01: 1019.7 sec\n",
      "  SPEAKER_00: 41.6 sec\n",
      "üëâ ‡∏ü‡∏±‡∏á preview ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏î‡∏ß‡πà‡∏≤ speaker ‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
      "\n",
      "üé¨ Analyze RKGQ3MvkFrM\n",
      "‚úÖ downloaded RKGQ3MvkFrM\n",
      "Speaker summary:\n",
      "  SPEAKER_03: 2971.2 sec\n",
      "  SPEAKER_01: 1554.6 sec\n",
      "  SPEAKER_04: 152.1 sec\n",
      "  SPEAKER_02: 82.2 sec\n",
      "  SPEAKER_00: 80.7 sec\n",
      "  SPEAKER_05: 50.2 sec\n",
      "üëâ ‡∏ü‡∏±‡∏á preview ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏î‡∏ß‡πà‡∏≤ speaker ‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n"
     ]
    }
   ],
   "source": [
    "youtube_ids = [\n",
    "    \"AxUEkqPH7iQ\",\n",
    "    \"zbo7Mk3ryaI\",\n",
    "    \"PYkZ1Z2pEc8\",\n",
    "    \"VN2VeBgR_3g\",\n",
    "    \"RKGQ3MvkFrM\"\n",
    "]\n",
    "\n",
    "os.makedirs(\"yt_audio\", exist_ok=True)\n",
    "os.makedirs(\"work_16k\", exist_ok=True)\n",
    "os.makedirs(\"data_22k\", exist_ok=True)\n",
    "os.makedirs(\"speaker_preview\", exist_ok=True)\n",
    "\n",
    "for yt_id in youtube_ids:\n",
    "    print(f\"\\nüé¨ Analyze {yt_id}\")\n",
    "\n",
    "    raw = f\"yt_audio/{yt_id}.wav\"\n",
    "    wav_16k = f\"work_16k/{yt_id}.wav\"\n",
    "    wav_22k = f\"data_22k/{yt_id}.wav\"\n",
    "\n",
    "    # 1. download\n",
    "    if not os.path.exists(raw):\n",
    "        download_youtube_audio(yt_id, \"yt_audio\")\n",
    "\n",
    "    # 2. convert\n",
    "    if not os.path.exists(wav_16k):\n",
    "        convert_audio(raw, wav_16k, 16000)\n",
    "\n",
    "    if not os.path.exists(wav_22k):\n",
    "        convert_audio(raw, wav_22k, 22050)\n",
    "\n",
    "    # 3. diarization\n",
    "    diar_segments = diarize(wav_16k)\n",
    "\n",
    "    # 4. summarize speaker\n",
    "    stats = summarize_speakers(diar_segments)\n",
    "    print(\"Speaker summary:\")\n",
    "    for spk, dur in sorted(stats.items(), key=lambda x: -x[1]):\n",
    "        print(f\"  {spk}: {dur:.1f} sec\")\n",
    "\n",
    "    # 5. export preview (‡∏ü‡∏±‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å speaker)\n",
    "    export_speaker_preview(\n",
    "        wav_22k_path=wav_22k,\n",
    "        diar_segments=diar_segments,\n",
    "        out_dir=f\"speaker_preview/{yt_id}\"\n",
    "    )\n",
    "\n",
    "    print(\"üëâ ‡∏ü‡∏±‡∏á preview ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏î‡∏ß‡πà‡∏≤ speaker ‡πÑ‡∏´‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b5c7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ Export dataset AxUEkqPH7iQ\n",
      "‚úÖ Finished dataset AxUEkqPH7iQ\n",
      "\n",
      "üì¶ Export dataset zbo7Mk3ryaI\n",
      "‚úÖ Finished dataset zbo7Mk3ryaI\n"
     ]
    }
   ],
   "source": [
    "TARGET_SPEAKER = {\n",
    "    \"AxUEkqPH7iQ\": \"SPEAKER_01\",\n",
    "    \"zbo7Mk3ryaI\": \"SPEAKER_00\"\n",
    "}\n",
    "\n",
    "youtube_ids = TARGET_SPEAKER.keys()\n",
    "\n",
    "os.makedirs(\"Lisa\", exist_ok=True)\n",
    "\n",
    "for yt_id in youtube_ids:\n",
    "    print(f\"\\nüì¶ Export dataset {yt_id}\")\n",
    "\n",
    "    wav_16k = f\"work_16k/{yt_id}.wav\"\n",
    "    wav_22k = f\"data_22k/{yt_id}.wav\"\n",
    "\n",
    "    # 1. sentence from VAD (16k)\n",
    "    sentences = get_sentences_16k(wav_16k)\n",
    "\n",
    "    # 2. diarization (reuse)\n",
    "    diar_segments = diarize(wav_16k)\n",
    "\n",
    "    # 3. export dataset (22k)\n",
    "    export_sentences_22k(\n",
    "        wav_22k_path=wav_22k,\n",
    "        sentences=sentences,\n",
    "        diar_segments=diar_segments,\n",
    "        out_dir=f\"dataset/{yt_id}\",\n",
    "        target_speaker=TARGET_SPEAKER[yt_id]\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Finished dataset {yt_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c9a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
