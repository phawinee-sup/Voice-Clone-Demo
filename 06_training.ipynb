{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d1750f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\tts_asr\\lib\\site-packages\\webrtcvad.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "SAMPLE_RATE = 22050\n",
    "N_MELS = 80\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SPEAKER_EMB_DIM = 64\n",
    "\n",
    "# =========================\n",
    "# Audio Utils\n",
    "# =========================\n",
    "def trim_silence(wav, sr):\n",
    "    vad = webrtcvad.Vad(2)\n",
    "    frame = int(sr * 0.02)  # 20ms\n",
    "    voiced = []\n",
    "\n",
    "    for i in range(0, len(wav) - frame, frame):\n",
    "        chunk = wav[i:i+frame]\n",
    "        pcm = (chunk * 32768).astype(np.int16).tobytes()\n",
    "        try:\n",
    "            if vad.is_speech(pcm, sr):\n",
    "                voiced.extend(chunk)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return np.array(voiced) if len(voiced) > 0 else wav\n",
    "\n",
    "\n",
    "def wav_to_mel(wav):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=wav,\n",
    "        sr=SAMPLE_RATE,\n",
    "        n_mels=N_MELS\n",
    "    )\n",
    "    return torch.FloatTensor(np.log(mel + 1e-6))\n",
    "\n",
    "# =========================\n",
    "# Dataset\n",
    "# =========================\n",
    "class TTSDataset(Dataset):\n",
    "    def __init__(self, manifest):\n",
    "        self.data = json.load(open(manifest))\n",
    "        speakers = sorted({d[\"speaker\"] for d in self.data})\n",
    "        self.spk2id = {s: i for i, s in enumerate(speakers)}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "\n",
    "        wav, _ = librosa.load(item[\"audio\"], sr=SAMPLE_RATE)\n",
    "        wav = trim_silence(wav, SAMPLE_RATE)\n",
    "\n",
    "        mel = wav_to_mel(wav)\n",
    "\n",
    "        text = torch.LongTensor(item[\"phonemes\"])\n",
    "\n",
    "        # pseudo duration\n",
    "        dur_value = max(1, mel.shape[1] // len(text))\n",
    "        duration = torch.ones(len(text)) * dur_value\n",
    "\n",
    "        speaker_id = torch.LongTensor([self.spk2id[item[\"speaker\"]]])\n",
    "\n",
    "        return text, duration, mel, speaker_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# =========================\n",
    "# LoRA Linear\n",
    "# =========================\n",
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_f, out_f, r=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.randn(out_f, in_f),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        self.A = nn.Parameter(torch.randn(r, in_f) * 0.01)\n",
    "        self.B = nn.Parameter(torch.randn(out_f, r) * 0.01)\n",
    "        self.scale = alpha / r\n",
    "\n",
    "    def forward(self, x):\n",
    "        base = x @ self.weight.T\n",
    "        lora = (x @ self.A.T @ self.B.T) * self.scale\n",
    "        return base + lora\n",
    "\n",
    "# =========================\n",
    "# Model\n",
    "# =========================\n",
    "class ResearchTTS_LoRA(nn.Module):\n",
    "    def __init__(self, vocab, dim=256, num_speakers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab, dim)\n",
    "        self.spk_embed = nn.Embedding(num_speakers, SPEAKER_EMB_DIM)\n",
    "\n",
    "        self.encoder = nn.LSTM(\n",
    "            dim + SPEAKER_EMB_DIM,\n",
    "            dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.duration = nn.Conv1d(dim, 1, 3, padding=1)\n",
    "\n",
    "        self.decoder = nn.LSTM(dim, dim, batch_first=True)\n",
    "\n",
    "        self.mel_proj = LoRALinear(dim, N_MELS)\n",
    "\n",
    "        # Freeze backbone\n",
    "        for p in self.embed.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.decoder.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, text, speaker_id):\n",
    "        x = self.embed(text)\n",
    "\n",
    "        spk = self.spk_embed(speaker_id).squeeze(1)\n",
    "        spk = spk.unsqueeze(1).expand(-1, x.size(1), -1)\n",
    "\n",
    "        x = torch.cat([x, spk], dim=-1)\n",
    "\n",
    "        x, _ = self.encoder(x)\n",
    "\n",
    "        dur = self.duration(x.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "        # ===== Length Regulator =====\n",
    "        expanded = []\n",
    "        for b in range(x.size(0)):\n",
    "            reps = torch.clamp(dur[b].round().long(), min=1)\n",
    "            expanded_seq = torch.repeat_interleave(x[b], reps, dim=0)\n",
    "            expanded.append(expanded_seq)\n",
    "\n",
    "        x = torch.nn.utils.rnn.pad_sequence(expanded, batch_first=True)\n",
    "\n",
    "        x, _ = self.decoder(x)\n",
    "        mel = self.mel_proj(x).transpose(1, 2)\n",
    "\n",
    "        return mel, dur\n",
    "\n",
    "# =========================\n",
    "# Loss\n",
    "# =========================\n",
    "def l1(a, b):\n",
    "    return torch.mean(torch.abs(a - b))\n",
    "\n",
    "# =========================\n",
    "# Train\n",
    "# =========================\n",
    "def train(manifest, saved_model_name):\n",
    "    dataset = TTSDataset(manifest)\n",
    "\n",
    "    # Auto vocab\n",
    "    max_token = max(max(d[\"phonemes\"]) for d in dataset.data)\n",
    "    vocab_size = max_token + 10\n",
    "    print(\"Auto vocab size:\", vocab_size)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    model = ResearchTTS_LoRA(\n",
    "        vocab=vocab_size,\n",
    "        num_speakers=len(dataset.spk2id)\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    optim = torch.optim.Adam(\n",
    "        [p for p in model.parameters() if p.requires_grad],\n",
    "        lr=1e-4\n",
    "    )\n",
    "\n",
    "    for epoch in range(30):\n",
    "        total = 0\n",
    "\n",
    "        for text, dur, mel, spk in tqdm(loader):\n",
    "\n",
    "            text = text.to(DEVICE)\n",
    "            mel = mel.to(DEVICE)\n",
    "            spk = spk.to(DEVICE)\n",
    "            dur = dur.to(DEVICE)\n",
    "\n",
    "            pred_mel, pred_dur = model(text, spk)\n",
    "\n",
    "            # Crop mel to match\n",
    "            min_len = min(pred_mel.size(2), mel.size(2))\n",
    "            pred_mel = pred_mel[:, :, :min_len]\n",
    "            mel = mel[:, :, :min_len]\n",
    "\n",
    "            loss = (\n",
    "                l1(pred_mel, mel) +\n",
    "                l1(pred_dur, dur)\n",
    "            )\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            total += loss.item()\n",
    "\n",
    "        print(f\"[LoRA][Multi-Spk] Epoch {epoch}: {total/len(loader):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), saved_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba87e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto vocab size: 5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [00:59<00:00, 42.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 0: 22.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:32<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 1: 16.1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:37<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 2: 14.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:39<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 3: 14.1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:43<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 4: 13.8483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:46<00:00, 23.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 5: 13.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:46<00:00, 23.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 6: 13.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:46<00:00, 24.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 7: 13.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:45<00:00, 24.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 8: 13.3754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:55<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 9: 13.3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:58<00:00, 21.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 10: 13.2602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:45<00:00, 24.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 11: 13.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:55<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 12: 13.1708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:51<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 13: 13.1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:46<00:00, 23.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 14: 13.1008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:57<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 15: 13.0698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:52<00:00, 22.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 16: 13.0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:54<00:00, 22.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 17: 13.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:56<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 18: 12.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:55<00:00, 22.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 19: 12.9591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:57<00:00, 21.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 20: 12.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:57<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 21: 12.9047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:56<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 22: 12.8785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:55<00:00, 22.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 23: 12.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:55<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 24: 12.8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:56<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 25: 12.8134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:50<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 26: 12.7965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:58<00:00, 21.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 27: 12.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:55<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 28: 12.7676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2558/2558 [01:56<00:00, 21.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 29: 12.7559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(\"manifest_whisper_rename_path.json\", \"research_tts_lora_multispk_whisper.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed9614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto vocab size: 5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:10<00:00, 36.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 0: 34.4155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:14<00:00, 34.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 1: 27.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:23<00:00, 31.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 2: 24.7394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:34<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 3: 23.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:39<00:00, 26.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 4: 23.2205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:43<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 5: 22.9487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:46<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 6: 22.7712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:48<00:00, 23.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 7: 22.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:48<00:00, 23.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 8: 22.5514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:47<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 9: 22.4759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:47<00:00, 24.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 10: 22.4114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:49<00:00, 23.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 11: 22.3550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:47<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 12: 22.3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:47<00:00, 24.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 13: 22.2658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:48<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 14: 22.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:47<00:00, 24.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 15: 22.1919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:49<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 16: 22.1575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:49<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 17: 22.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:47<00:00, 24.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 18: 22.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:48<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 19: 22.0585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:49<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 20: 22.0251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:49<00:00, 23.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 21: 21.9948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:48<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 22: 21.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:48<00:00, 23.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 23: 21.9442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:49<00:00, 23.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 24: 21.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:44<00:00, 24.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 25: 21.9110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:52<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 26: 21.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:50<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 27: 21.8887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:51<00:00, 23.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 28: 21.8792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2590/2590 [01:52<00:00, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LoRA][Multi-Spk] Epoch 29: 21.8701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(\"manifest_pathumma_rename_path.json\", \"research_tts_lora_multispk_pathumma.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62d73d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts_asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
